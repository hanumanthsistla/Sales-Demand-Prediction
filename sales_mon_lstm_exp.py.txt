# -*- coding: utf-8 -*-
"""
Created on Thu Oct 15 13:21:28 2020

@author: 119540
"""
# -*- coding: utf-8 -*-
"""
Created on Wed Oct 14 12:35:38 2020

https://towardsdatascience.com/predicting-sales-611cb5a252de

Dataset Location:F:/ML_Project_April_2020/Kaggle_Projects/demand-forecasting-kernels-only

model: lstm

@author: 119540
"""
from datetime import datetime, timedelta,date
import pandas as pd
# %matplotlib inline
import matplotlib.pyplot as plt
import numpy as np
# from __future__ import division

import warnings
warnings.filterwarnings("ignore")

import chart_studio.plotly as py
import plotly.offline as pyoff
import plotly.graph_objs as go

#import Keras
import keras
import tensorflow
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.callbacks import EarlyStopping
# from tensorflow.keras.utils import np_utils
from tensorflow.keras.layers import LSTM
from sklearn.model_selection import KFold, cross_val_score, train_test_split

#initiate plotly
pyoff.init_notebook_mode()

#read the data in csv
df_sales = pd.read_csv('F:/ML_Project_April_2020/Kaggle_Projects/demand-forecasting-kernels-only/train.csv')

#convert date field from string to datetime
df_sales['date'] = pd.to_datetime(df_sales['date'])

#show first 10 rows
print(df_sales.head(10))

# Task: Forecast monthly total sales
# Aggregate data at the monthly level and sum up the sales column.
# Represent month in date field as its first day

df_sales['date'] = df_sales['date'].dt.year.astype('str') + '-' + df_sales['date'].dt.month.astype('str') + '-01'
df_sales['date'] = pd.to_datetime(df_sales['date'])

#groupby date and sum the sales

df_sales = df_sales.groupby('date').sales.sum().reset_index()

print(df_sales.head())

#plot monthly sales

plot_data = [
    go.Scatter(
        x=df_sales['date'],
        y=df_sales['sales'],
    )
]
plot_layout = go.Layout(
        title='Montly Sales'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
pyoff.iplot(fig)

# py.iplot(fig).show()

# Obviously, it is not stationary and has an increasing trend over the months. 
# One method is to get the difference in sales compared to the previous month and build the model on it:

#create a new dataframe to model the difference
df_diff = df_sales.copy()
#add previous sales to the next row
df_diff['prev_sales'] = df_diff['sales'].shift(1)
#drop the null values and calculate the difference
df_diff = df_diff.dropna()
df_diff['diff'] = (df_diff['sales'] - df_diff['prev_sales'])


print(df_diff.head(10))

# Let’s plot it and check if it is stationary now:
    
#plot sales diff

plot_data = [
    go.Scatter(
        x=df_diff['date'],
        y=df_diff['diff'],
    )
]
plot_layout = go.Layout(
        title='Montly Sales Diff'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
pyoff.iplot(fig)

# We need to use previous monthly sales data to forecast the next ones. 
# The look-back period may vary for every model. Ours will be 12 for this example.

# So what we need to do is to create columns from lag_1 to lag_12 
# and assign values by using shift() method:
    
#create dataframe for transformation from time series to supervised

df_supervised = df_diff.drop(['prev_sales'],axis=1)

#adding lags

for inc in range(1,13):
    field_name = 'lag_' + str(inc)
    df_supervised[field_name] = df_supervised['diff'].shift(inc)
#drop null values
df_supervised = df_supervised.dropna().reset_index(drop=True)

print(df_supervised.head(10))

# How useful are our features for prediction?
# Adjusted R-squared is the answer. 
# It tells us how good our features explain the variation in our label (lag_1 to lag_12 for diff, in our example).

# Import statsmodels.formula.api

import statsmodels.formula.api as smf
# Define the regression formula
model1 = smf.ols(formula='diff ~ lag_1', data=df_supervised)
# Fit the regression
model_fit1 = model1.fit()
# Extract the adjusted r-squared
regression_adj_rsq1 = model_fit1.rsquared_adj
print(regression_adj_rsq1)

# Add entire feature set

# Define the regression formula - select all lags
model2 = smf.ols(formula='diff ~ lag_1 + lag_2 + lag_3 + lag_4 + lag_5 + lag_6 + lag_7 + lag_8 + lag_9 + lag_10 + lag_11 + lag_12', data=df_supervised)
# Fit the regression
model_fit2 = model2.fit()
# Extract the adjusted r-squared
regression_adj_rsq2 = model_fit2.rsquared_adj
print(regression_adj_rsq2)


# Split our data into train and test sets. As the test set, we have selected the last 6 months’ sales.

#import MinMaxScaler and create a new dataframe for LSTM model
from sklearn.preprocessing import MinMaxScaler
df_model = df_supervised.drop(['sales','date'],axis=1)#split train and test set
train_set, test_set = df_model[0:-6].values, df_model[-6:].values

# As the scaler, we are going to use MinMaxScaler, which will scale each future between -1 and 1:
    
#apply Min Max Scaler
scaler = MinMaxScaler(feature_range=(-1, 1))
scaler = scaler.fit(train_set)
# reshape training set
train_set = train_set.reshape(train_set.shape[0], train_set.shape[1])
train_set_scaled = scaler.transform(train_set)# reshape test set
test_set = test_set.reshape(test_set.shape[0], test_set.shape[1])
test_set_scaled = scaler.transform(test_set)


# Building the LSTM model:
# Everything is ready to build our first deep learning model. Let’s create feature and label sets from scaled datasets:
 
X_train, y_train = train_set_scaled[:, 1:], train_set_scaled[:, 0:1]
X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])

X_test, y_test = test_set_scaled[:, 1:], test_set_scaled[:, 0:1]
X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])

# fit our LSTM model

model = Sequential()
model.add(LSTM(4, batch_input_shape=(1, X_train.shape[1], X_train.shape[2]), stateful=True))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(X_train, y_train, epochs=100, batch_size=1, verbose=1, shuffle=False)

# The code block above prints how the model improves itself and reduce the error in each epoch:

# Let’s do the prediction and see how the results look like:
    
y_pred = model.predict(X_test,batch_size=1)

#for multistep prediction, you need to replace X_test values with the predictions coming from t-1

# Results look similar but it doesn’t tell us much because these are scaled data that shows the difference. 
# How we can see the actual sales prediction?
# First, we need to do the inverse transformation for scaling:

#reshape y_pred

y_pred = y_pred.reshape(y_pred.shape[0], 1, y_pred.shape[1])
#rebuild test set for inverse transform
pred_test_set = []
for index in range(0,len(y_pred)):
    print (np.concatenate([y_pred[index],X_test[index]],axis=1))
pred_test_set.append(np.concatenate([y_pred[index],X_test[index]],axis=1))

#reshape pred_test_set
pred_test_set = np.array(pred_test_set)
pred_test_set = pred_test_set.reshape(pred_test_set.shape[0], pred_test_set.shape[2])
#inverse transform
pred_test_set_inverted = scaler.inverse_transform(pred_test_set)


# Second, we need to build the dataframe has the dates and the predictions.
# Transformed predictions are showing the difference. We should calculate the predicted sales numbers:

#create dataframe that shows the predicted sales

result_list = []
sales_dates = list(df_sales[-7:].date)
act_sales = list(df_sales[-7:].sales)
for index in range(0,len(pred_test_set_inverted)):
    result_dict = {}
    result_dict['pred_value'] = int(pred_test_set_inverted[index][0] + act_sales[index])
    result_dict['date'] = sales_dates[index+1]
    result_list.append(result_dict)
df_result = pd.DataFrame(result_list)

#for multistep prediction, replace act_sales with the predicted sales
print('Predicted Sales Values')
print('\n-----------------------')
print(df_result)


# We’ve predicted the next six months’ sales numbers. 
# Let’s check them in the plot to see how good is our model:

#merge with actual sales dataframe
df_sales_pred = pd.merge(df_sales,df_result,on='date',how='left')#plot actual and predicted
plot_data = [
    go.Scatter(
        x=df_sales_pred['date'],
        y=df_sales_pred['sales'],
        name='actual'
    ),
        go.Scatter(
        x=df_sales_pred['date'],
        y=df_sales_pred['pred_value'],
        name='predicted'
    )
    
]
plot_layout = go.Layout(
        title='Sales Prediction'
    )
fig = go.Figure(data=plot_data, layout=plot_layout)
pyoff.iplot(fig)

# One improvement we can do for this model is to add holidays, breaks, and other seasonal effects. 
# They can be simply added as a new feature.By using this model, we have our baseline sales predictions. 
# But how we can predict the effect of a promotion on sales?

#drop null values
df_supervised = df_supervised.dropna().reset_index(drop=True)

